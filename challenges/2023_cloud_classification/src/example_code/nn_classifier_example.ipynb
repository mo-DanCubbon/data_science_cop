{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Starter code for Cloud Classification Challenge\n",
    "\n",
    "This code is designed as starter point for your development. You do not have to use it, but feel free to use it if you do not know where to start.\n",
    "\n",
    "The [Pytorch](https://pytorch.org/) collection of packages is used to define and train the model, and this code is adapted from their [introductory tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "\n",
    "Other machine learning python packages that you may wish to use include [TensorFlow](https://www.tensorflow.org/overview) and [scikit-learn](https://scikit-learn.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SLURM_NTASKS_PER_NODE'] = '1' # set to prevent pytorch_lightning.trainer from breaking\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional.classification import multiclass_accuracy\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom Dataset for sat images\n",
    "\n",
    "Dataset instance reads in the directory to the images and their labels.\n",
    "The dataloader enables simple iteration over these images when training and testing a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for label data\n",
    "def get_label_dict():\n",
    "    label_dict = {\"Fish\": 0,\n",
    "                  \"Flower\": 1,\n",
    "                  \"Gravel\": 2,\n",
    "                  \"Sugar\": 3}\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "def sat_label_transform(label):\n",
    "    label_dict = get_label_dict()\n",
    "    return label_dict[label]\n",
    "\n",
    "\n",
    "def sat_label_transform_inv(num):\n",
    "    label_dict = get_label_dict()\n",
    "    ret_list = [key for key in label_dict.keys() if label_dict[key]==num]\n",
    "    return ret_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform for images.\n",
    "# Converts to float and scales values to range 0-1.\n",
    "# Normalisation using the mean/std used by AlexNet.\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class for loading the satellite image into a Dataset\n",
    "class SatImageDataset(Dataset):\n",
    "    def __init__(self, labels_file, img_dir, transform=img_transform, target_transform=sat_label_transform):\n",
    "        self.img_labels = pd.read_csv(labels_file)[:1000] # TODO: remove, used for testing\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[\"Image\"].iloc[idx])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels[\"Label\"].iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and testing data using instances of the SatImageDataset defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_files_dir = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/train/\"\n",
    "train_files_labels = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/train/train_labels.csv\"\n",
    "\n",
    "# Create train images dataloader\n",
    "train_images = SatImageDataset(labels_file=train_files_labels, img_dir=train_files_dir)\n",
    "train_dataloader = DataLoader(train_images, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "test_files_dir = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/test/\"\n",
    "test_files_labels = \"/data/users/meastman/understanding_clouds_kaggle/input/single_labels/224s/test/test_labels.csv\"\n",
    "\n",
    "# Create test images dataloader\n",
    "test_images = SatImageDataset(labels_file=test_files_labels, img_dir=test_files_dir)\n",
    "test_dataloader = DataLoader(test_images, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network\n",
    "\n",
    "This is a single layer neural network. For more details on the individual layers, and for further options if you wish to create a different model architecture see [the tutorial](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n",
    "\n",
    "Note that the input to the layer has size `150528 = 3*224*224`. The input images are 224 * 224 pixels, with 3 RGB channels.\n",
    "\n",
    "The output layer has size 4 which matches the number of cloud categories available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_aware_focal_loss(logits, targets, weights, alpha=1.0, gamma=2.0):\n",
    "    ce_loss = F.cross_entropy(logits, targets, weights, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "\n",
    "def weighted_dist(arr):\n",
    "    # Calculate the center of the array\n",
    "    center = np.array(arr.shape) / 2\n",
    "    \n",
    "    # Create an array of distances from each point to the center\n",
    "    distances = np.linalg.norm(np.indices(arr.shape) - center[:, np.newaxis, np.newaxis], axis=0)\n",
    "    \n",
    "    # Avoid division by zero for the center point\n",
    "    distances[int(center[0]), int(center[1])] = 1.0\n",
    "    \n",
    "    # Calculate the value divided by distance for each point\n",
    "    values_divided_by_distances = arr / distances\n",
    "    \n",
    "    # Calculate the mean of the values divided by distances\n",
    "    result = np.mean(values_divided_by_distances)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "class NNCloudClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.resconv1 = torch.nn.Conv2d(in_channels=64, out_channels=256, kernel_size=1)\n",
    "        self.dropout = torch.nn.Dropout2d(p=0.2)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(64)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(128)\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = torch.nn.BatchNorm2d(256)\n",
    "        self.conv6 = torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = torch.nn.BatchNorm2d(256)\n",
    "        self.conv7 = torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = torch.nn.BatchNorm2d(256)\n",
    "        self.conv8 = torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = torch.nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(256 * 7 * 7, 128)  # Assuming input size is 224x224\n",
    "        self.fc2 = torch.nn.Linear(128, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 16)\n",
    "        self.fc4 = torch.nn.Linear(16, 8)\n",
    "        self.fc5 = torch.nn.Linear(12, 8)\n",
    "        self.fc6 = torch.nn.Linear(8, 4)\n",
    "        \n",
    "        self.test_outputs = []\n",
    "        self.avg_test_acc = None\n",
    "        self.confusion = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Input data\n",
    "\n",
    "        :return: output - mnist digit label for the input image\n",
    "        \"\"\"\n",
    "\n",
    "        x = -1 * x[:, 0, :, :]\n",
    "        batch_size = x.shape[0]\n",
    "        x_std = torch.std(x, dim=(1, 2)).reshape(batch_size, 1)\n",
    "        x_mean = torch.mean(x, dim=(1, 2)).reshape(batch_size, 1)\n",
    "        x = np.abs(np.fft.fftshift(np.fft.fft2(x, axes=(1,2))))\n",
    "        x_fft_std = torch.std(torch.tensor(x, dtype=torch.float), dim=(1, 2)).reshape(batch_size, 1)\n",
    "        x_fft_freq_spread = np.zeros((batch_size, 1))\n",
    "        for i in range(batch_size):\n",
    "            x_fft_freq_spread[i] = weighted_dist(x[i])\n",
    "        \n",
    "        x = torch.tensor(x.reshape(batch_size, 1, 224, 224), dtype=torch.float)\n",
    "        # Initial convolution and pooling\n",
    "        x1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x2 = self.pool(F.relu(self.bn2(self.conv2(x1))))\n",
    "        x3 = self.pool(F.relu(self.bn3(self.conv3(x2))))\n",
    "        x3 = self.dropout(x3)\n",
    "\n",
    "        # Residual connections\n",
    "        x4 = self.pool(F.relu(self.bn4(self.conv4(x3))))\n",
    "        x5 = self.pool(F.relu(self.bn5(self.conv5(x4))))\n",
    "        \n",
    "        # Merge early layers with later layers\n",
    "\n",
    "        x3_resized = F.avg_pool2d(x3, kernel_size=(4, 4))\n",
    "        x3_resized = self.resconv1(x3_resized)\n",
    "\n",
    "        x5 = x5 + x3_resized  # Adding residual connection\n",
    "        \n",
    "        x6 = torch.relu(self.bn6(self.conv6(x5)))\n",
    "        x7 = torch.relu(self.bn7(self.conv7(x6)))\n",
    "        x8 = torch.relu(self.bn8(self.conv8(x7)))\n",
    "        \n",
    "        x8 = x8 + x5 # Adding residual connection\n",
    "        \n",
    "        x = x8.view(x8.size(0), -1)  # Flatten the tensor\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.cat((x, x_std.to(torch.float)), dim=1)\n",
    "        x = torch.cat((x, x_mean.to(torch.float)), dim=1)\n",
    "        x = torch.cat((x, x_fft_std.to(torch.float)), dim=1)\n",
    "        x = torch.cat((x, torch.tensor(x_fft_freq_spread, dtype=torch.float64)), dim=1)\n",
    "        x = torch.relu(self.fc5(x.to(torch.float)))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        #w = torch.Tensor([0.95,1.1,1.05,0.75])\n",
    "        w = torch.Tensor([1.0, 1.0, 1.0, 0.9])\n",
    "        loss = class_aware_focal_loss(logits, y, w)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc = multiclass_accuracy(pred, y, num_classes=4)\n",
    "\n",
    "        # Use the current of PyTorch logger\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Performs test and computes the accuracy of the model\n",
    "\n",
    "        :param test_batch: Batch data\n",
    "        :param batch_idx: Batch indices\n",
    "\n",
    "        :return: output - Testing accuracy\n",
    "        \"\"\"\n",
    "        x, y = test_batch\n",
    "        output = self.forward(x)\n",
    "        _, y_hat = torch.max(output, dim=1)\n",
    "        test_acc = multiclass_accuracy(y_hat, y, num_classes=4)\n",
    "        self.test_outputs.append(test_acc)\n",
    "        self.confusion.append(confusion_matrix(y.numpy(), y_hat.numpy()))\n",
    "        return {\"test_acc\": test_acc}\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Computes average test accuracy score\n",
    "        \"\"\"\n",
    "        self.avg_test_acc = torch.stack(self.test_outputs).mean()\n",
    "        total_confusion = np.zeros((4, 4), dtype=int)\n",
    "    \n",
    "        # Sum up confusion matrices from all batches\n",
    "        for x in self.confusion:\n",
    "            total_confusion += np.array(x)\n",
    "            \n",
    "        self.log(\"avg_test_acc\", self.avg_test_acc, sync_dist=True)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(total_confusion, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"Predicted labels\")\n",
    "        plt.ylabel(\"True labels\")\n",
    "        plt.xticks(np.arange(4))\n",
    "        plt.yticks(np.arange(4))\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        self.test_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "    \n",
    "    \n",
    "# class NNCloudClassifierNew(pl.LightningModule):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.l1 = torch.nn.Linear(3, 4)\n",
    "        \n",
    "#         self.test_outputs = []\n",
    "#         self.avg_test_acc = None\n",
    "#         self.confusion = []\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         :param x: Input data\n",
    "\n",
    "#         :return: output - mnist digit label for the input image\n",
    "#         \"\"\"\n",
    "#         batch_size = x.shape[0]\n",
    "\n",
    "        \n",
    "#         x = x[:, 0, :, :]\n",
    "#         x_fft = np.abs(np.fft.fftshift(np.fft.fft2(x, axes=(1,2))))\n",
    "#         x_fft_std = torch.std(torch.tensor(x_fft), dim=(1,2))\n",
    "        \n",
    "#         cov_matrices = np.zeros((batch_size, 224*224, 224*224), dtype=np.float32)\n",
    "#         elipticalness = []\n",
    "# #         print(\"1\")\n",
    "#         for i in range(batch_size):\n",
    "#             flattened_ffts = x_fft[i].reshape(1, -1)        \n",
    "#             cov_matrices[i] = np.cov(flattened_ffts, rowvar=False)\n",
    "#             eigvals, eigvecs = np.linalg.eigh(cov_matrices[i])\n",
    "#             elipticalness_ratio = eigvals[:, -1] / eigvals[:, 0]\n",
    "#             elipticalness.append(elipticalness_ratio)\n",
    "        \n",
    "#         print(elipticalness)\n",
    "            \n",
    "# #         print(\"2\")\n",
    "# #         eigenvals, eigenvecs = np.linalg.eigh(cov_mat)\n",
    "# #         print(\"3\")\n",
    "# #         eliptical_ratios = eigenvals[:, -1] / eigenvalues[:, 0]\n",
    "# #         print(\"4\")\n",
    "# #         print(eliptical_ratios)\n",
    "\n",
    "#         x_mean = torch.mean(x, dim=(1,2))\n",
    "#         x_std = torch.std(x, dim=(1,2))\n",
    "        \n",
    "#         x_tens = torch.zeros((batch_size, 3))\n",
    "#         x_tens[:, 0] = x_mean\n",
    "#         x_tens[:, 1] = x_std\n",
    "#         x_tens[:, 2] = x_fft_std/500\n",
    "                        \n",
    "#         x = torch.relu(self.l1(x_tens))\n",
    "#         return x\n",
    "\n",
    "#     def training_step(self, batch, batch_nb):\n",
    "#         x, y = batch\n",
    "#         logits = self(x)\n",
    "#         loss = F.cross_entropy(logits, y)\n",
    "#         pred = logits.argmax(dim=1)\n",
    "#         acc = multiclass_accuracy(pred, y, num_classes=4)\n",
    "\n",
    "#         # Use the current of PyTorch logger\n",
    "#         self.log(\"train_loss\", loss, on_epoch=True)\n",
    "#         self.log(\"acc\", acc, on_epoch=True)\n",
    "#         return loss\n",
    "    \n",
    "#     def test_step(self, test_batch, batch_idx):\n",
    "#         \"\"\"\n",
    "#         Performs test and computes the accuracy of the model\n",
    "\n",
    "#         :param test_batch: Batch data\n",
    "#         :param batch_idx: Batch indices\n",
    "\n",
    "#         :return: output - Testing accuracy\n",
    "#         \"\"\"\n",
    "#         x, y = test_batch\n",
    "#         output = self.forward(x)\n",
    "#         _, y_hat = torch.max(output, dim=1)\n",
    "#         test_acc = multiclass_accuracy(y_hat, y, num_classes=4)\n",
    "#         self.test_outputs.append(test_acc)\n",
    "#         self.confusion.append(confusion_matrix(y.numpy(), y_hat.numpy()))\n",
    "#         return {\"test_acc\": test_acc}\n",
    "    \n",
    "#     def on_test_epoch_end(self):\n",
    "#         \"\"\"\n",
    "#         Computes average test accuracy score\n",
    "#         \"\"\"\n",
    "#         self.avg_test_acc = torch.stack(self.test_outputs).mean()\n",
    "#         total_confusion = np.zeros((4, 4), dtype=int)\n",
    "    \n",
    "#         # Sum up confusion matrices from all batches\n",
    "#         for x in self.confusion:\n",
    "#             total_confusion += np.array(x)\n",
    "            \n",
    "#         self.log(\"avg_test_acc\", self.avg_test_acc, sync_dist=True)\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         plt.imshow(total_confusion, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "#         plt.title(\"Confusion Matrix\")\n",
    "#         plt.colorbar()\n",
    "#         plt.xlabel(\"Predicted labels\")\n",
    "#         plt.ylabel(\"True labels\")\n",
    "#         plt.xticks(np.arange(4))\n",
    "#         plt.yticks(np.arange(4))\n",
    "#         plt.savefig(\"confusion_matrix.png\")\n",
    "#         self.test_outputs.clear()\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient().list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(\"run_id: {}\".format(r.info.run_id))\n",
    "    print(\"artifacts: {}\".format(artifacts))\n",
    "    print(\"params: {}\".format(r.data.params))\n",
    "    print(\"metrics: {}\".format(r.data.metrics))\n",
    "    print(\"tags: {}\".format(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "2023/08/17 13:56:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/mlflow/pytorch/_lightning_autolog.py:351: UserWarning: Autologging is known to be compatible with pytorch-lightning versions between 1.0.5 and 2.0.5 and may not succeed with packages outside this range.\"\n",
      "\n",
      "   | Name     | Type        | Params\n",
      "------------------------------------------\n",
      "0  | conv1    | Conv2d      | 160   \n",
      "1  | bn1      | BatchNorm2d | 32    \n",
      "2  | conv2    | Conv2d      | 4.6 K \n",
      "3  | bn2      | BatchNorm2d | 64    \n",
      "4  | conv3    | Conv2d      | 18.5 K\n",
      "5  | resconv1 | Conv2d      | 16.6 K\n",
      "6  | dropout  | Dropout2d   | 0     \n",
      "7  | bn3      | BatchNorm2d | 128   \n",
      "8  | conv4    | Conv2d      | 73.9 K\n",
      "9  | bn4      | BatchNorm2d | 256   \n",
      "10 | conv5    | Conv2d      | 295 K \n",
      "11 | bn5      | BatchNorm2d | 512   \n",
      "12 | conv6    | Conv2d      | 590 K \n",
      "13 | bn6      | BatchNorm2d | 512   \n",
      "14 | conv7    | Conv2d      | 590 K \n",
      "15 | bn7      | BatchNorm2d | 512   \n",
      "16 | conv8    | Conv2d      | 590 K \n",
      "17 | bn8      | BatchNorm2d | 512   \n",
      "18 | pool     | MaxPool2d   | 0     \n",
      "19 | fc1      | Linear      | 1.6 M \n",
      "20 | fc2      | Linear      | 4.1 K \n",
      "21 | fc3      | Linear      | 528   \n",
      "22 | fc4      | Linear      | 136   \n",
      "23 | fc5      | Linear      | 104   \n",
      "24 | fc6      | Linear      | 36    \n",
      "------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.170    Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7285e39b4ddc47efb5776afabf9a15fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=6` reached.\n",
      "2023/08/17 13:59:21 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:480: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/h03/dcubbon/.conda/envs/cloud_class/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a53c8a63fe45b582148eb54cf3c95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Runningstage.testing metric      DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      avg_test_acc                 0.25\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "run_id: 5c8f6f89be2e48fcafa5eae929cfcfac\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'epochs': '6', 'optimizer_name': 'Adam', 'lr': '0.02', 'betas': '(0.9, 0.999)', 'eps': '1e-08', 'weight_decay': '0', 'amsgrad': 'False', 'maximize': 'False', 'foreach': 'None', 'capturable': 'False', 'differentiable': 'False', 'fused': 'None'}\n",
      "metrics: {'train_loss': 0.724059522151947, 'train_loss_step': 0.7266092896461487, 'acc': 0.25066667795181274, 'acc_step': 0.3333333432674408, 'train_loss_epoch': 0.724059522151947, 'acc_epoch': 0.25066667795181274, 'avg_test_acc': 0.25}\n",
      "tags: {'Mode': 'testing'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize our model\n",
    "classifier = NNCloudClassifier()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=6, devices=1, num_nodes=1)\n",
    "\n",
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(classifier, train_dataloader)\n",
    "    trainer.test(classifier, test_dataloader)\n",
    "    mlflow.log_metric('avg_test_acc', classifier.avg_test_acc)\n",
    "    \n",
    "# fetch the auto logged parameters and metrics\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-cloud_class Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-cloud_class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
